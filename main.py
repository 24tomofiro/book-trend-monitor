import os
import yaml
import pandas as pd
from datetime import datetime
import pytz
from dotenv import load_dotenv

# è‡ªä½œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.crawler import BookCrawler
from src.visualizer import BookVisualizer

def get_time_slot(hour):
    """å®Ÿè¡Œæ™‚åˆ»ï¼ˆ24æ™‚é–“åˆ¶ï¼‰ã‹ã‚‰æ™‚é–“å¸¯ãƒ©ãƒ™ãƒ«ã‚’è¿”ã™"""
    if 5 <= hour < 11:
        return "morning"
    elif 11 <= hour < 17:
        return "afternoon"
    elif 17 <= hour < 23:
        return "evening"
    else:
        return "night"

def main():
    # 1. åˆæœŸè¨­å®šã¨ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
    # GitHub Actionsç­‰ã®ã‚µãƒ¼ãƒãƒ¼ç’°å¢ƒã§ã‚‚æ—¥æœ¬æ™‚é–“ã‚’æ­£ç¢ºã«ç¶­æŒ
    jst = pytz.timezone('Asia/Tokyo')
    now = datetime.now(jst)
    print(f"[{now.isoformat()}] Starting Book Trend Monitor...")

    load_dotenv()
    api_key = os.environ.get("GOOGLE_API_KEY")
    cx = os.environ.get("GOOGLE_CX")
    
    if not api_key or not cx:
        print("âŒ Error: GOOGLE_API_KEY or GOOGLE_CX is not set in environment variables.")
        return

    # 2. è¨­å®š(config/books.yaml)ã®èª­ã¿è¾¼ã¿
    config_path = "config/books.yaml"
    if not os.path.exists(config_path):
        print(f"âŒ Error: {config_path} not found.")
        return
        
    with open(config_path, "r", encoding="utf-8") as f:
        config = yaml.safe_load(f)
    
    if not config or 'books' not in config:
        print("âŒ Error: Invalid config file format.")
        return

    # 3. ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®åˆæœŸåŒ–
    crawler = BookCrawler(api_key, cx)
    time_slot = get_time_slot(now.hour)
    results = []

    # 4. ãƒ‡ãƒ¼ã‚¿åé›†ãƒ«ãƒ¼ãƒ— (Reach/åºƒãŒã‚Š ã¨ Depth/æ·±ã• ã®ä¸¡ç«‹)
    print(f"ğŸ” Scanning for {len(config['books'])} books (Slot: {time_slot})...")
    
    for book in config['books']:
        title = book['title']
        # ç›¸å¯¾çš„ãªæŠ½å‡ºå‰²åˆï¼ˆä¸Šä½xx%ï¼‰ã‚’å–å¾—ã€‚è¨­å®šãŒãªã„å ´åˆã¯100%ï¼ˆå…¨ä»¶ï¼‰ã‚’è¡¨ç¤º
        percentile = book.get('top_percentile', 100)
        
        # æ¤œç´¢ã‚¯ã‚¨ãƒªã®æ§‹ç¯‰
        exclude_query = " ".join([f"-{w}" for w in book.get('exclude', [])])
        keyword = "(" + " OR ".join(book['keywords']) + ") " + exclude_query
        
        print(f"  - Processing: {title} (Target: Top {percentile}%)")
        
        # Webèª¿æŸ» (åºƒãŒã‚Š/Reach ã®ä»¶æ•°ã®ã¿åˆ©ç”¨)
        web_count, _ = crawler.get_data(keyword)
        
        # Xèª¿æŸ» (æ·±ã•/Depth ã‚’å«ã‚ãŸ URL|ã‚¹ã‚³ã‚¢ ã®ãƒªã‚¹ãƒˆã‚’å–å¾—)
        x_count, x_links_with_scores = crawler.get_data(
            keyword, 
            site="x.com", 
            top_percentile=percentile
        )
        
        results.append({
            "date": now.strftime("%Y-%m-%d"),
            "time_slot": time_slot,
            "book_title": title,
            "web_count": web_count,
            "x_count": x_count,
            "sentiment": 0.5, # å¿…è¦ã«å¿œã˜ã¦å°†æ¥çš„ã«æ„Ÿæƒ…åˆ†æã‚’è¿½åŠ å¯èƒ½
            # "url|score" å½¢å¼ã§ä¿å­˜ã—ã€Visualizerå´ã§æ•°å€¤ã‚’åˆ†é›¢è¡¨ç¤ºã™ã‚‹
            "top_links": ",".join(x_links_with_scores) if x_links_with_scores else "ãªã—"
        })

    # 5. CSVä¿å­˜ (ãƒ‡ãƒ¼ã‚¿ã®æ°¸ç¶šåŒ–ã¨é‡è¤‡æ’é™¤)
    df_new = pd.DataFrame(results)
    csv_path = "data/processed/daily_stats.csv"
    os.makedirs(os.path.dirname(csv_path), exist_ok=True)
    
    if os.path.exists(csv_path) and os.path.getsize(csv_path) > 0:
        try:
            df_old = pd.read_csv(csv_path)
            df_final = pd.concat([df_old, df_new], ignore_index=True)
            print(f"ğŸ“– Existing data loaded from {csv_path}")
        except Exception as e:
            print(f"âš ï¸ Could not read existing CSV ({e}). Creating new file.")
            df_final = df_new
    else:
        df_final = df_new
        print(f"ğŸ†• Creating new CSV at {csv_path}")
    
    # åŒä¸€ã®æ—¥ä»˜ãƒ»æ™‚é–“å¸¯ãƒ»æ›¸ç±ãŒã‚ã‚Œã°æœ€æ–°ã®å®Ÿè¡Œçµæœã‚’ä¿æŒ
    if not df_final.empty:
        df_final.drop_duplicates(subset=['date', 'time_slot', 'book_title'], keep='last', inplace=True)
        # æ™‚ç³»åˆ—é †ã«ã‚½ãƒ¼ãƒˆã—ã¦ä¿å­˜
        df_final.sort_values(by=['date', 'time_slot'], ascending=True, inplace=True)
      
    df_final.to_csv(csv_path, index=False, encoding="utf-8-sig")
    print(f"âœ… Successfully updated {csv_path}")

    # 6. å¯è¦–åŒ–å‡¦ç† (ZenGakuTVãƒ–ãƒ©ãƒ³ãƒ‰ã®ãƒ‡ã‚¶ã‚¤ãƒ³é©ç”¨)
    print("ğŸ“Š Generating charts and portal...")
    visualizer = BookVisualizer(csv_path)
    
    # å„æ›¸ç±ã®å€‹åˆ¥ãƒ¬ãƒãƒ¼ãƒˆã¨ãƒãƒ¼ã‚¿ãƒ«ç”»é¢ã‚’ç”Ÿæˆ
    visualizer.generate_charts()
    visualizer.generate_portal()
    
    print(f"âœ¨ All tasks completed at {datetime.now(jst).strftime('%H:%M:%S')}")

if __name__ == "__main__":
    main()